{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":93770,"databundleVersionId":11159819,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nThis notebook demonstrates the complete workflow for setting up and training a YOLO model. The process includes:\n- Data augmentation\n- Hyperparameter optimization using Optuna\n- Inference for generating submission files\n\nAlthough we use the \"You Only Look Once\" (YOLO) model, this challenge might have you looking twice before starting the training process!","metadata":{"_uuid":"19c5ba05-a476-4c85-a005-ae1ef5a2433f","_cell_guid":"341db91b-155e-4f4a-b999-376123997678","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"**Note:** Selecting the optimal model size, batch size, and number of epochs is critical. Launching training without careful parameter tuning may result in wasted time.","metadata":{"_uuid":"dfe14be9-7be0-470f-a32e-1f64187ca9df","_cell_guid":"5e501b01-c175-4d74-9c1e-6c68b7219821","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"!pip install ultralytics\n!pip install albumentations\n!pip install optuna","metadata":{"_uuid":"bc9287b0-bbe9-4c43-ae65-760e02c51875","_cell_guid":"de2c4903-6f98-4e7f-bc18-9a9da02c7114","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Import Libraries\n\nIn this section, we import the libraries required for:\n- File and image handling (`os`, `cv2`, `shutil`)\n- XML parsing (`xml.etree.ElementTree`)\n- Data splitting (`sklearn.model_selection`)\n- Data augmentation (`albumentations`)\n- Model training and inference (`torch`, `ultralytics`)\n- Others such as `numpy` and `pathlib`","metadata":{"_uuid":"b2f6bd09-8985-48b2-9fd8-a2b95779b032","_cell_guid":"f2bd9fd5-5740-4f17-a122-9ed1a62be700","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import os\nimport cv2\nimport xml.etree.ElementTree as ET\nfrom sklearn.model_selection import train_test_split\nimport albumentations as A\nimport shutil\nimport torch\nfrom ultralytics import YOLO\nfrom pathlib import Path\nimport numpy as np","metadata":{"_uuid":"9ca87d19-137e-45db-9fa8-387a91abc1da","_cell_guid":"a2174a37-8d93-4117-b26e-329fef331fa2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transforming XML Annotations\n\nYOLO requires annotations in a specific format. The function below converts annotations from XML (Pascal VOC) to YOLO format. Only objects labeled as `nodule` are processed.","metadata":{"_uuid":"48e7c4f4-eed7-43ea-afb4-a18554b4f5e1","_cell_guid":"0e327f12-8cac-4cca-93e1-51ce8fea8c7b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def convert_xml_to_yolo(xml_path):\n    \"\"\"Convert XML annotations to YOLO format, separating class labels.\"\"\"\n    tree = ET.parse(xml_path)\n    root = tree.getroot()\n    size = root.find('size')\n    width = int(size.find('width').text)\n    height = int(size.find('height').text)\n    \n    bboxes = []\n    class_labels = []\n    for obj in root.findall('object'):\n        if obj.find('name').text != 'nodule':\n            continue\n        bndbox = obj.find('bndbox')\n        xmin = float(bndbox.find('xmin').text)\n        ymin = float(bndbox.find('ymin').text)\n        xmax = float(bndbox.find('xmax').text)\n        ymax = float(bndbox.find('ymax').text)\n        \n        x_center = (xmin + xmax) / 2.0 / width\n        y_center = (ymin + ymax) / 2.0 / height\n        box_width = (xmax - xmin) / width\n        box_height = (ymax - ymin) / height\n        \n        x_center = min(max(x_center, 1e-6), 1.0)\n        y_center = min(max(y_center, 1e-6), 1.0)\n        box_width = min(max(box_width, 1e-6), 1.0)\n        box_height = min(max(box_height, 1e-6), 1.0)\n        \n        bboxes.append([x_center, y_center, box_width, box_height])\n        class_labels.append(0)\n    \n    return bboxes, class_labels","metadata":{"_uuid":"11769830-3daf-4484-983c-69c45f540f44","_cell_guid":"48505f36-657b-48e6-bb0a-de8824889963","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Augmentation\n\nWe utilize the Albumentations library to augment our chest X-ray images. The augmentation pipeline includes:\n- Random brightness and contrast adjustments\n- Addition of Gaussian noise\n- Rotation (up to 15°)\n- CLAHE (Contrast Limited Adaptive Histogram Equalization) for improved contrast\n- Slight shifts and scales\n\nCLAHE is especially effective for X-ray images as it enhances contrast while controlling noise amplification.\n\n> **CLAHE:** Contrast Limited AHE (CLAHE) is a variant of adaptive histogram equalization where the contrast amplification is limited, reducing the risk of noise amplification.","metadata":{"_uuid":"ff0c296d-8ee7-47e6-a113-696689e1559d","_cell_guid":"cac2d9ec-c77e-43f0-8ba6-a02bac1d0734","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import albumentations as A\n\ndef get_augmentation_pipeline():\n    \"\"\"Enhanced Albumentations pipeline for chest X-ray augmentation.\"\"\"\n    return A.Compose([\n        A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.8),\n        A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n        A.Rotate(limit=15, p=0.5),  # Rotate up to 15°\n        A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),\n        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=0, p=0.3),  # Slight shifting and scaling\n    ], bbox_params=A.BboxParams(format='yolo', min_visibility=0.1, label_fields=['labels']))","metadata":{"_uuid":"09cfb40f-c008-4895-af89-8b71bc8c7311","_cell_guid":"2e428831-3cca-49e6-914a-e3910eed8f57","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def augment_dataset(original_images_dir, original_annos_dir, output_images_dir, output_labels_dir, num_augmentations=1):\n    \"\"\"Augment dataset by generating additional samples based on literature guidelines.\"\"\"\n    os.makedirs(output_images_dir, exist_ok=True)\n    os.makedirs(output_labels_dir, exist_ok=True)\n    \n    augmentation = get_augmentation_pipeline()\n    \n    for xml_file in os.listdir(original_annos_dir):\n        if not xml_file.endswith('.xml'):\n            continue\n        base_name = os.path.splitext(xml_file)[0]\n        img_path = os.path.join(original_images_dir, f\"{base_name}.jpg\")\n        xml_path = os.path.join(original_annos_dir, xml_file)\n        \n        img = cv2.imread(img_path)\n        if img is None:\n            print(f\"Warning: Failed to load {img_path}\")\n            continue\n        \n        bboxes, class_labels = convert_xml_to_yolo(xml_path)\n        \n        orig_img_path = os.path.join(output_images_dir, f\"{base_name}.jpg\")\n        orig_label_path = os.path.join(output_labels_dir, f\"{base_name}.txt\")\n        if not os.path.exists(orig_img_path):\n            shutil.copy(img_path, orig_img_path)\n        if not os.path.exists(orig_label_path) and bboxes:\n            with open(orig_label_path, 'w') as f:\n                for bbox in bboxes:\n                    f.write(f\"0 {' '.join(map(str, bbox))}\\n\")\n        \n        # Generate augmented samples for each image\n        for i in range(num_augmentations):\n            aug_img_name = f\"{base_name}_aug_{i}.jpg\"\n            aug_label_name = f\"{base_name}_aug_{i}.txt\"\n            aug_img_path = os.path.join(output_images_dir, aug_img_name)\n            aug_label_path = os.path.join(output_labels_dir, aug_label_name)\n            \n            if not os.path.exists(aug_img_path):\n                augmented = augmentation(image=img, bboxes=bboxes, labels=class_labels)\n                aug_img = augmented['image']\n                aug_bboxes = augmented['bboxes']\n                aug_labels = augmented['labels']\n                \n                cv2.imwrite(aug_img_path, aug_img)\n                if aug_bboxes and not os.path.exists(aug_label_path):\n                    with open(aug_label_path, 'w') as f:\n                        for bbox, label in zip(aug_bboxes, aug_labels):\n                            f.write(f\"{label} {' '.join(map(str, bbox))}\\n\")\n\n    print(f\"Augmented dataset saved to {output_images_dir} and {output_labels_dir}\")","metadata":{"_uuid":"779fc9df-1389-4cb4-8277-b69201182ad7","_cell_guid":"922e00d2-97a6-4376-b8a9-f46297b1598b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"original_images = '/kaggle/input/pulmonary-nodule/train/jpg'\noriginal_annos = '/kaggle/input/pulmonary-nodule/train/anno'\ndataset_dir = '/kaggle/working/pulmonary-nodule'\nimages_dir = os.path.join(dataset_dir, 'images')\nlabels_dir = os.path.join(dataset_dir, 'labels')\n\nos.makedirs(images_dir, exist_ok=True)\nos.makedirs(labels_dir, exist_ok=True)\ntrain_images_dir = os.path.join(images_dir, 'train')\nval_images_dir = os.path.join(images_dir, 'val')\ntrain_labels_dir = os.path.join(labels_dir, 'train')\nval_labels_dir = os.path.join(labels_dir, 'val')\nos.makedirs(train_images_dir, exist_ok=True)\nos.makedirs(val_images_dir, exist_ok=True)\nos.makedirs(train_labels_dir, exist_ok=True)\nos.makedirs(val_labels_dir, exist_ok=True)","metadata":{"_uuid":"25199fc5-76a8-4830-b1c3-da8f04a26287","_cell_guid":"5f7daeb0-17ca-41ab-b462-9556deb03c5f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If you wish to remove the existing augmented dataset before re-generating it, uncomment the cell below.","metadata":{"_uuid":"4cefbb7d-eb92-4143-8ef2-a8ca8204fcd6","_cell_guid":"eb695cba-6dd5-45c2-9366-3f27e1481a1d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# # Clear existing augmented training data\n# if os.path.exists(train_images_dir):\n#     shutil.rmtree(train_images_dir)\n# os.makedirs(train_images_dir, exist_ok=True)\n#\n# if os.path.exists(train_labels_dir):\n#     shutil.rmtree(train_labels_dir)\n# os.makedirs(train_labels_dir, exist_ok=True)","metadata":{"_uuid":"0ee1473a-cf69-40ae-9441-33544bf84cc1","_cell_guid":"304fd7f8-5995-4499-851b-352193b93b0a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xml_files = [f for f in os.listdir(original_annos) if f.endswith('.xml')]\nfilenames = [os.path.splitext(f)[0] for f in xml_files]\ntrain_filenames, val_filenames = train_test_split(filenames, test_size=0.2, random_state=42)\n\n# Overwrite augmented training data\naugment_dataset(original_images, original_annos, train_images_dir, train_labels_dir, num_augmentations=1)\n\n# Process the validation set with safety checks\nfor filename in val_filenames:\n    src_image = os.path.join(original_images, f\"{filename}.jpg\")\n    dst_image = os.path.join(val_images_dir, f\"{filename}.jpg\")\n    \n    if not os.path.exists(dst_image):\n        shutil.copy(src_image, dst_image)\n    \n    xml_path = os.path.join(original_annos, f\"{filename}.xml\")\n    label_path = os.path.join(val_labels_dir, f\"{filename}.txt\")\n    \n    if not os.path.exists(label_path):\n        bboxes, class_labels = convert_xml_to_yolo(xml_path)\n        if bboxes:\n            with open(label_path, 'w') as f:\n                for bbox in bboxes:\n                    f.write(f\"0 {' '.join(map(str, bbox))}\\n\")\n\nprint(\"Validation set prepared with safety checks.\")\n\n# Repeat augmentation and validation set processing if needed\nxml_files = [f for f in os.listdir(original_annos) if f.endswith('.xml')]\nfilenames = [os.path.splitext(f)[0] for f in xml_files]\ntrain_filenames, val_filenames = train_test_split(filenames, test_size=0.2, random_state=42)\naugment_dataset(original_images, original_annos, train_images_dir, train_labels_dir, num_augmentations=1)\n\nfor filename in val_filenames:\n    src_image = os.path.join(original_images, f\"{filename}.jpg\")\n    dst_image = os.path.join(val_images_dir, f\"{filename}.jpg\")\n    \n    if not os.path.exists(dst_image):\n        shutil.copy(src_image, dst_image)\n    \n    xml_path = os.path.join(original_annos, f\"{filename}.xml\")\n    label_path = os.path.join(val_labels_dir, f\"{filename}.txt\")\n    \n    if not os.path.exists(label_path):\n        bboxes, class_labels = convert_xml_to_yolo(xml_path)\n        if bboxes:\n            with open(label_path, 'w') as f:\n                for bbox in bboxes:\n                    f.write(f\"0 {' '.join(map(str, bbox))}\\n\")\n\nprint(\"Validation set prepared with safety checks.\")","metadata":{"_uuid":"a1bd8a90-bfc3-4922-8856-3172c7c37e67","_cell_guid":"3b36f6ac-c2ec-4f73-8651-28460a4ea06e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_yaml_path = '/kaggle/working/pulmonary-nodule/data.yaml'\ndata_yaml_content = \"\"\"\ntrain: /kaggle/working/pulmonary-nodule/images/train\nval: /kaggle/working/pulmonary-nodule/images/val\nnc: 1\nnames: ['nodule']\n\"\"\"\nwith open(data_yaml_path, 'w') as f:\n    f.write(data_yaml_content)\n\nif os.path.exists(data_yaml_path):\n    print(\"data.yaml exists!\")\n    with open(data_yaml_path, 'r') as f:\n        print(\"Contents of data.yaml:\")\n        print(f.read())\nelse:\n    print(\"Error: data.yaml was not created!\")","metadata":{"_uuid":"0eefa016-7cfb-4090-8de4-624db09cfc1a","_cell_guid":"d784251b-14a3-42de-b842-c3244ed87e3d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hyperparameter Tuning\n\nWe use **Optuna** to optimize the hyperparameters for our YOLO model. Although a single trial may take considerable time, random parameter sampling helps us explore the search space effectively. Additionally, model weights are saved after each epoch so that you can resume or use the best available checkpoint even if training is interrupted.","metadata":{"_uuid":"574a0181-7bd6-496e-99eb-ee127b4382e3","_cell_guid":"dc1060cf-da87-4eac-a980-db5dd87c0d18","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import optuna\nfrom ultralytics import YOLO\nimport os\nimport json\nfrom datetime import datetime\n\nclass CheckpointCallback:\n    def __init__(self, checkpoint_dir='optuna_checkpoints'):\n        self.checkpoint_dir = checkpoint_dir\n        os.makedirs(checkpoint_dir, exist_ok=True)\n        self.checkpoint_file = os.path.join(checkpoint_dir, 'study_checkpoint.json')\n        \n    def __call__(self, study: optuna.study.Study, trial: optuna.trial.FrozenTrial):\n        checkpoint_data = {\n            'study_name': study.study_name,\n            'direction': study.direction.name,\n            'best_trial': {\n                'number': study.best_trial.number,\n                'value': study.best_trial.value,\n                'params': study.best_trial.params\n            },\n            'trials_completed': len(study.trials),\n            'datetime': datetime.now().isoformat()\n        }\n        \n        with open(self.checkpoint_file, 'w') as f:\n            json.dump(checkpoint_data, f, indent=4)\n\ndef load_checkpoint(checkpoint_dir='optuna_checkpoints'):\n    checkpoint_file = os.path.join(checkpoint_dir, 'study_checkpoint.json')\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file, 'r') as f:\n            return json.load(f)\n    return None\n\ndef objective(trial):\n    # Define hyperparameters to optimize\n    lr0 = trial.suggest_float('lr0', 1e-4, 1e-2, log=True)\n    batch_size = trial.suggest_int('batch_size', 4, 16, step=4)\n    momentum = trial.suggest_float('momentum', 0.8, 0.95)\n    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n    iou = trial.suggest_float('iou', 0.4, 0.7)\n    \n    # Create unique run directory for this trial\n    run_dir = f'runs/trial_{trial.number}'\n    os.makedirs(run_dir, exist_ok=True)\n    \n    # Load model with pre-trained weights\n    model = YOLO('yolo11m.pt')\n    \n    print(f\"\\nTrial {trial.number}: Starting YOLOv11n training\")\n    print(f\"Parameters: lr0={lr0}, batch={batch_size}, momentum={momentum}\")\n    \n    try:\n        # Train with trial-specific hyperparameters\n        results = model.train(\n            data=data_yaml_path,\n            epochs=50,\n            imgsz=1024,\n            batch=batch_size,\n            patience=10,\n            lr0=lr0,\n            cos_lr=True,\n            momentum=momentum,\n            weight_decay=weight_decay,\n            iou=iou,\n            augment=True,\n            resume=False,\n            project=run_dir,\n            name='exp',\n            exist_ok=True,\n            save_period=1,  # Save model after every epoch\n            save=True      # Enable model saving\n        )\n        \n        # Extract validation mAP50\n        metrics = results.results_dict\n        val_mAP50 = metrics.get('metrics/mAP50(B)', 0.0)\n        \n        # Save trial results\n        trial_results = {\n            'trial_number': trial.number,\n            'params': trial.params,\n            'mAP50': val_mAP50,\n            'model_dir': os.path.join(run_dir, 'exp')\n        }\n        \n        with open(os.path.join(run_dir, 'trial_results.json'), 'w') as f:\n            json.dump(trial_results, f, indent=4)\n            \n        return val_mAP50\n        \n    except Exception as e:\n        print(f\"Error in trial {trial.number}: {str(e)}\")\n        return float('-inf')\n\n# Data path\ndata_yaml_path = '/kaggle/working/pulmonary-nodule/data.yaml'\n\n# Verify data paths\nprint(\"Checking data paths...\")\nrequired_paths = {\n    'Train': '/kaggle/working/pulmonary-nodule/images/train',\n    'Val': '/kaggle/working/pulmonary-nodule/images/val',\n    'data.yaml': data_yaml_path\n}\n\nfor name, path in required_paths.items():\n    exists = os.path.exists(path)\n    print(f\"{name} path exists: {exists}\")\n    if not exists:\n        raise FileNotFoundError(f\"Required path not found: {path}\")\n\n# Load existing checkpoint if available\ncheckpoint_data = load_checkpoint()\nif checkpoint_data:\n    print(\"\\nResuming from previous checkpoint:\")\n    print(f\"Completed trials: {checkpoint_data['trials_completed']}\")\n    print(f\"Best trial so far: {checkpoint_data['best_trial']['value']}\")\n\n# Create and configure study\nstudy = optuna.create_study(\n    direction='maximize',\n    study_name='yolo_optimization',\n    load_if_exists=True\n)\n\n# Add checkpoint callback\ncheckpoint_callback = CheckpointCallback()\n\n# Run optimization\nn_trials = 1\nprint(f\"\\nStarting optimization with {n_trials} trials...\")\nstudy.optimize(\n    objective,\n    n_trials=n_trials,\n    callbacks=[checkpoint_callback]\n)\n\n# Print final results\nprint(\"\\nOptimization completed!\")\nprint(\"\\nBest trial:\")\ntrial = study.best_trial\nprint(f\"  Value (mAP50): {trial.value}\")\nprint(\"  Parameters:\")\nfor key, value in trial.params.items():\n    print(f\"    {key}: {value}\")","metadata":{"_uuid":"4595e27e-81e2-45ad-9775-3ad861a850bf","_cell_guid":"a89805a1-8c02-4b96-9149-81dc6cfddd80","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference\n\nFor inference, we load the best model weights obtained from the training process. You can adjust the confidence threshold to optimize your detection performance. Multiple submissions might be needed to fine-tune the final score.","metadata":{"_uuid":"1f480a71-4b0e-4956-967e-6a4123471530","_cell_guid":"6d935b96-da93-416a-8936-19b8ac1af49c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torch\nfrom ultralytics import YOLO\nimport cv2\nimport pandas as pd\nfrom glob import glob\nimport json\nimport os\nimport numpy as np\n\n# Load the optimized YOLOv11 model\nmodel = YOLO('/kaggle/working/runs/trial_0/exp/weights/best.pt')  # Updated model path\nmodel.to('cuda' if torch.cuda.is_available() else 'cpu')\n\ntest_images = glob('/kaggle/input/pulmonary-nodule/test/jpg/*.jpg')\nsubmission = []\n\nfor img_path in test_images:\n    filename = os.path.basename(img_path).split(\".\")[0]\n    img = cv2.imread(img_path)\n        \n    # Inference with Test Time Augmentation (TTA)\n    results = model(img, augment=True)\n    \n    objects = []\n    for result in results:\n        boxes = result.boxes.xyxy.cpu().numpy()\n        scores = result.boxes.conf.cpu().numpy()\n        labels = result.boxes.cls.cpu().numpy()\n        \n        for box, score, label in zip(boxes, scores, labels):\n            if score > 0.411 and label == 0:\n                objects.append({\n                    'class': 'nodule',\n                    'bbox': {\n                        'xmin': int(box[0]),\n                        'ymin': int(box[1]),\n                        'xmax': int(box[2]),\n                        'ymax': int(box[3])\n                    }\n                })\n    \n    objects_str = json.dumps(objects)\n    submission.append([filename, 1024, 1024, 3, objects_str])\n\ndf = pd.DataFrame(submission, columns=['filename', 'width', 'height', 'depth', 'objects'])\ndf.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"Submission saved to /kaggle/working/submission.csv\")","metadata":{"_uuid":"fc551ad2-447d-45c0-812a-d9072b67144f","_cell_guid":"96a14156-ece3-4fef-b1df-7ed62f73810a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusion\n\nThank you for exploring this notebook! If you appreciate this approach or have any questions or feedback, please feel free to reach out or upvote the project. Your feedback is invaluable and will help improve future work.","metadata":{"_uuid":"69b464ab-0e23-4e2a-8ef6-4e49d92bac42","_cell_guid":"ef11fb5b-8a0a-418e-83e5-d84bfdbcf063","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}}]}